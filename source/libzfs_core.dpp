module libzfs_core;

/+
	work towards Dlang wrapper for libzfs-core
+/

#define uint32_t uint

#include <stdint.h>
#include <libzfs_core.h>
#include <libnvpair.h>

import std.string:toStringz, fromStringz;
import std.exception;
import taggedalgebraic;
import std.conv:to;

alias toCString = toStringz;
alias fromCString = fromStringz;

struct SILdoc {string value; }

void rename(string from, string to)
{
	auto result = lzc_rename(from.toCString, to.toCString);
	enforce(result==0,"something went wrong");
}

// extern(C) void nvlist_free(nvlist_t*);

enum DatasetType
{
	zfs = LZC_DATSET_TYPE_ZFS,
	zvol = LZC_DATSET_TYPE_ZVOL,
}


enum VdevType
{
	root,
	mirror,
	replacing,
	raidz,
	disk,
	file,
	missing,
	hole,
	spare,
	log,
	l2cache,
}

enum PoolStatus
{
	corruptCache,
	missingDevR,                         /* missing device with replicas */
	missingDevNr,                        /* missing device with no replicas */
	corruptLabelR,                       /* bad device label with replicas */
	corruptLabelNr,                      /* bad device label with no replicas */
	badGUIDSum,                          /* sum of device guids didn't match */
	corruptPool,                         /* pool metadata is corrupted */
	corruptData,                         /* data errors in user (meta)data */
	failingDev,                          /* device experiencing errors */
	versionNewer,                        /* newer on-disk version */
	hostidMismatch,                      /* last accessed by another system */
	hosidActive,                         /* currently active on another system */
	hostidRequired,                      /* multihost=on and hostid=0 */
	ioFailureWait,                       /* failed I/O, failmode 'wait' */
	ioFailureContinue,                   /* failed I/O, failmode 'continue' */
	ioFailureMap,                        /* ailed MMP, failmode not 'panic' */
	badLog,                              /* cannot read log chain(s) */
	errata,                              /* informational errata available */

	/*
	 * If the pool has unsupported features but can still be opened in
	 * read-only mode, its status is ZPOOL_STATUS_UNSUP_FEAT_WRITE. If the
	 * pool has unsupported features but cannot be opened at all, its
	 * status is ZPOOL_STATUS_UNSUP_FEAT_READ.
	 */
	unsupFeatRead,  /* unsupported features for read */
	unsupFeatWrite, /* unsupported features for write */

	/*
	 * These faults have no corresponding message ID.  At the time we are
	 * checking the status, the original reason for the FMA fault (I/O or
	 * checksum errors) has been lost.
	 */
	faultedDevR,  /* faulted device with replicas */
	faultedDevNr, /* faulted device with no replicas */

	/*
	 * The following are not faults per se, but still an error possibly
	 * requiring administrative attention.  There is no corresponding
	 * message ID.
	 */
	versionOlder, /* older legacy on-disk version */
	featDisabled, /* supported features are disabled */
	resilvering,  /* device being resilvered */
	offlineDev,   /* device online */
	removedDev,   /* removed device */

	/*
	 * Finally, the following indicates a healthy pool.
	 */
	ok,
}

// Possible ZFS pool states
enum PoolState
{
	active,            					/* In active use		*/
	exported,                           /* Explicitly exported		*/
	destroyed,                          /* Explicitly destroyed		*/
	spare,                              /* Reserved for hot spare use	*/
	l2cache,                            /* Level 2 ARC device		*/
	uninitialized,                      /* Internal spa_t state		*/
	unavail,                            /* Internal libzfs state	*/
	potentiallyActive                  /* Internal libzfs state	*/
}

// Pool properties. Enumerates available ZFS pool properties. Use it to access
// pool properties either to read or set soecific property.
enum PoolProperty
{
	cont,
	inval,
	name,
	size,
	capacity,
	altroot,
	health,
	guid,
	version_,
	bootfs,
	delegation,
	autoReplace,
	cacheFile,
	failureMode,
	listSnaps,
	autoExpand,
	dedupDitto,
	dedupRatio,
	free,
	allocated,
	readOnly,
	ashift,
	comment,
	expandSize,
	freeing,
	fragmentation,
	leaked,
	maxBlockSize,
	tName,
	maxNodeSize,
	multiHost,
	poolNumProps,
}


/*
 * Dataset properties are identified by these constants and must be added to
 * the end of this list to ensure that external consumers are not affected
 * by the change. If you make any changes to this list, be sure to update
 * the property table in module/zcommon/zfs_prop.c.
 */
enum DatasetProperty
{
	cont,
	bad,
	type,
	creation,
	used,
	available,
	referenced,
	compressRatio,
	mounted,
	origin,
	quota,
	reservation,
	volSize,
	volBlockSize,
	recordsize,
	mountpoint,
	sharenfs,
	checksum,
	compression,
	atime,
	devices,
	exec,
	setuid,
	readonly,
	zoned,
	snapdir,
	private_, /* not exposed to user, temporary */
	aclinherit,
	createTXG, /* not exposed to the user */
	name,      /* not exposed to the user */
	canmount,
	iscsioptions, /* not exposed to the user */
	xattr,
	numclones, /* not exposed to the user */
	copies,
	version_,
	utf8only,
	normalize,
	case_,
	vscan,
	nbmand,
	sharesmb,
	refquota,
	refreservation,
	guid,
	primarycache,
	secondarycache,
	usedsnap,
	usedds,
	usedchild,
	usedrefreserv,
	useraccounting, /* not exposed to the user */
	stmfShareinfo,  /* not exposed to the user */
	deferDestroy,
	userrefs,
	logbias,
	unique,   /* not exposed to the user */
	objsetid, /* not exposed to the user */
	dedup,
	mlslabel,
	sync,
	dnodeSize,
	refratio,
	written,
	clones,
	logicalused,
	logicalreferenced,
	inconsistent, /* not exposed to the user */
	volmode,
	filesystemLimit,
	snapshotLimit,
	filesystemCount,
	snapshotCount,
	snapdev,
	acltype,
	selinuxContext,
	selinuxFsContext,
	selinuxDefContext,
	selinuxRootContext,
	relatime,
	redundantMetadata,
	overlay,
	prevSnap,
	receiveResumeToken,
	encryption,
	keyLocation,
	keyFormat,
	pBKDF2Salt,
	pBKDF2Iters,
	encryptionRoot,
	keyGUID,
	keyStatus,
	remapTXG, /* not exposed to the user */
	datasetNumProps,
}


// ZFS errors
enum ZfsError
{
	success            = 0,            /* no error -- success */
	nomem              , // = 2000 << iota, /* out of memory */
	badprop,                           /* invalid property value */
	propreadonly,                      /* cannot set readonly property */
	proptype,                          /* property does not apply to dataset type */
	propnoninherit,                    /* property is not inheritable */
	propspace,                         /* bad quota or reservation */
	badtype,                           /* dataset is not of appropriate type */
	busy,                              /* pool or dataset is busy */
	exists,                            /* pool or dataset already exists */
	noent,                             /* no such pool or dataset */
	badstream,                         /* bad backup stream */
	dsreadonly,                        /* dataset is readonly */
	voltoobig,                         /* volume is too large for 32-bit system */
	invalidname,                       /* invalid dataset name */
	badrestore,                        /* unable to restore to destination */
	badbackup,                         /* backup failed */
	badtarget,                         /* bad attach/detach/replace target */
	nodevice,                          /* no such device in pool */
	baddev,                            /* invalid device to add */
	noreplicas,                        /* no valid replicas */
	resilvering,                       /* currently resilvering */
	badversion,                        /* unsupported version */
	poolunavail,                       /* pool is currently unavailable */
	devoverflow,                       /* too many devices in one vdev */
	badpath,                           /* must be an absolute path */
	crosstarget,                       /* rename or clone across pool or dataset */
	zoned,                             /* used improperly in local zone */
	mountfailed,                       /* failed to mount dataset */
	umountfailed,                      /* failed to unmount dataset */
	unsharenfsfailed,                  /* unshare(1M) failed */
	sharenfsfailed,                    /* share(1M) failed */
	perm,                              /* permission denied */
	nospc,                             /* out of space */
	fault,                             /* bad address */
	io,                                /* I/O error */
	intr,                              /* signal received */
	isspare,                           /* device is a hot spare */
	invalconfig,                       /* invalid vdev configuration */
	recursive,                         /* recursive dependency */
	nohistory,                         /* no history object */
	poolprops,                         /* couldn't retrieve pool props */
	poolNotsup,                        /* ops not supported for this type of pool */
	poolInvalarg,                      /* invalid argument for this pool operation */
	nametoolong,                       /* dataset name is too long */
	openfailed,                        /* open of device failed */
	nocap,                             /* couldn't get capacity */
	labelfailed,                       /* write of label failed */
	badwho,                            /* invalid permission who */
	badperm,                           /* invalid permission */
	badpermset,                        /* invalid permission set name */
	nodelegation,                      /* delegated administration is disabled */
	unsharesmbfailed,                  /* failed to unshare over smb */
	sharesmbfailed,                    /* failed to share over smb */
	badcache,                          /* bad cache file */
	isl2CACHE,                         /* device is for the level 2 ARC */
	vdevnotsup,                        /* unsupported vdev type */
	notsup,                            /* ops not supported on this dataset */
	activeSpare,                       /* pool has active shared spare devices */
	unplayedLogs,                      /* log device has unplayed logs */
	reftagRele,                        /* snapshot release: tag not found */
	reftagHold,                        /* snapshot hold: tag already exists */
	tagtoolong,                        /* snapshot hold/rele: tag too long */
	pipefailed,                        /* pipe create failed */
	threadcreatefailed,                /* thread create failed */
	postsplitOnline,                   /* onlining a disk after splitting it */
	scrubbing,                         /* currently scrubbing */
	noScrub,                           /* no active scrub */
	diff,                              /* general failure of zfs diff */
	diffdata,                          /* bad zfs diff data */
	poolreadonly,                      /* pool is in read-only mode */
	unknown,
}

// vdev states are ordered from least to most healthy.
// A vdev that's CantOpen or below is considered unusable.
enum VdevState
{
	unknown,				// Uninitialized vdev
	closed,                    // Not currently open
	offline,                   // Not allowed to open
	removed,                   // Explicitly removed from system
	cantOpen,                  // Tried to open, but failed
	faulted,                   // External request to fault device
	degraded,                  // Replicated vdev with unhealthy kids
	healthy,                   // Presumed good
}

// vdev aux states.  When a vdev is in the CantOpen state, the aux field
// of the vdev stats structure uses these constants to distinguish why.
enum VdevAux
{
	none,
	openFailed,				    // ldi_open_*() or vn_open() failed
	corruptData,                 // bad label or disk contents
	noReplicas,                  // insufficient number of replicas
	badGUIDSum,                  // vdev guid sum doesn't match
	tooSmall,                    // vdev size is too small
	badLabel,                    // the label is OK but invalid
	versionNewer,                // on-disk version is too new
	versionOlder,                // on-disk version is too old
	unsupFeat,                   // unsupported features
	spared,                      // hot spare used in another pool
	errExceeded,                 // too many errors
	ioFailure,                   // experienced I/O failure
	badLog,                      // cannot read log chain(s)
	external,                    // external diagnosis
	splitPool,                   // vdev was split off into another pool
}



struct ZfsErrorResult
{
	int num;
	string text;
}


shared static this()
{
	enforce(libzfs_core_init() == 0, "Error initialising ZFS");
}

shared static ~this()
{
	libzfs_core_fini();
}	

version(None)
{
	auto toList(string[string] args)
	{
		nvlist_t** pNvList = nvlist_alloc(nvlistp,1,0); // UNIQUE NAME == 1
		enforce(pNvList !is null, "nvlist_alloca failed");
		scope(exit)
			nvlist_free(pNvList);
		return dictToNvList(args,pNvList);
	}

	auto asDict(nv_list* list)
	{
		string[string] ret;

		pair = nvlist_next_nvpair(list,null);
		while (pair !is null)
		{
			auto name = nvpair_name(pair).fromCString;
			auto id = type(pair);
		}
	}

	auto type(nvpair* pair)
	{
		auto id = nvpair_typie(pair);
	}
}

enum NvType
{
	unknown = DATA_TYPE_UNKNOWN,
	boolean = DATA_TYPE_BOOLEAN,
	byte_ = DATA_TYPE_BYTE,
	short_ = DATA_TYPE_INT16,
	ushort_ = DATA_TYPE_UINT16,
	int_ = DATA_TYPE_INT32,
	uint_ = DATA_TYPE_UINT32,
	long_ = DATA_TYPE_INT64,
	ulong_ = DATA_TYPE_UINT64,
	string_ = DATA_TYPE_STRING,
	byteArray = DATA_TYPE_BYTE_ARRAY,
	shortArray = DATA_TYPE_INT16_ARRAY,
	ushortArray = DATA_TYPE_UINT16_ARRAY,
	intArray = DATA_TYPE_INT32_ARRAY,
	uintArray = DATA_TYPE_UINT32_ARRAY,
	longArray = DATA_TYPE_INT64_ARRAY,
	ulongArray = DATA_TYPE_UINT64_ARRAY,
	stringArray = DATA_TYPE_STRING_ARRAY,
	hrTime = DATA_TYPE_HRTIME,
	nvList = DATA_TYPE_NVLIST,
	nvListArray = DATA_TYPE_NVLIST_ARRAY,
	booleanValue = DATA_TYPE_BOOLEAN_VALUE,
	int8 = DATA_TYPE_INT8,
	uint8 = DATA_TYPE_UINT8,
	booleanArray = DATA_TYPE_BOOLEAN_ARRAY,
	int8Array = DATA_TYPE_INT8_ARRAY,
	uint8Array =  DATA_TYPE_UINT8_ARRAY,
	double_ = DATA_TYPE_DOUBLE
}

union ZfsValueUnion
{
	bool boolean;
	byte byte_;
	char int8Value;
	ubyte ubyteValue;
	short short_;
	ushort ushort_;
	int int_;
	uint uint_;
	long long_;
	ulong ulong_;
	string string_;
	bool[] booleanArray;
	char[] charArray;
	ubyte[] ubyteArray;
	short[] shortArray;
	ushort[] ushortArray;
	int[] intArray;
	uint[] uintArray;
	long[] longArray;
	ulong[] ulongArray;
	string[] stringArray;
	//hrtime hrTime;
	//ZfsValue value;
	//ZfsValue[] valueArray;
	//ZfsValue[string] valueDict;
	double double_;
	ZfsValueUnion[] valueArray;
	ZfsValueUnion[string] valueDict;
}

alias ZfsValue = TaggedAlgebraic!ZfsValueUnion;

/+
nvlist_t* asList(ZfsValue[string] values)
{
	foreach(entry;values.byKeyValue)
	{
		final switch(entry.value.kind)
		{
			case ZfsValue.Kind.valueDict:
				nvlist_add_nvlist(list,entry.key.toCString,entry.value.asCValue);
				break;
	
			case ZfsValue.Kind.valueArray:
				nvlist_add_array(list,entry.key.toCString,entry.value.asCValue);
				break;

			case ZfsValue.
+/
		
void create(string filesystem, DatasetType dataSetType, ubyte[] wkeyData)
{
	auto props = nvlistAlloc(NV_UNIQUE_NAME, 0);
	scope(exit)
		nvlistFree(props);
	auto result = lzc_create(filesystem.toCString, cast(lzc_dataset_type) dataSetType, props,wkeyData.ptr,wkeyData.length.to!uint_t);
	enforce(result==0,"something went wrong");
}

void clone(string filesystem, string origin)
{
	auto props = nvlistAlloc(NV_UNIQUE_NAME, 0);
	scope(exit)
		nvlistFree(props);
	auto result = lzc_clone(filesystem.toCString,origin.toCString,props);
	enforce(result==0,"something went wrong");
}

string promote(string filesystem)
{
	char[16384] buf;
	auto result = lzc_promote(filesystem.toCString,buf.ptr, buf.length);
	enforce(result==0,"something went wrong");
	return buf.ptr.fromCString.idup;
}

void remap(string filesystem)
{
	auto result = lzc_remap(filesystem.toCString);
	enforce(result==0,"something went wrong");
}


ulong snapRangeSpace(string firstSnap, string lastSnap)
{
	ulong ret;
	auto result = lzc_snaprange_space(firstSnap.toCString, lastSnap.toCString,&ret);
	enforce(result>=0, "zfs error");
	return ret;
}

@SILdoc(`
Forces all in-core dirty data to be written to the primary pool storage and not the ZIL.
Params:
    string poolname: the name of the pool.
    bool force: whether to force uberblock update even if there is no dirty data.
`)
auto poolSync(string poolName, bool force)
{
	import std.format: format;
	nvlist_t* outnvl;
	auto innvl = nvlistAlloc(NV_UNIQUE_NAME, 0);
	if (force)
		nvlistAddBoolean(innvl,"force");
	auto result = lzc_sync(poolName.toCString,innvl,&outnvl);
	enforce(result ==0, format!"error during pool sync: %s"(result));
}

auto holdSnapshot(nvlist_t* holds, int cleanUpFD)
{
	import std.format:format;
	nvlist_t* errlist;
	auto result = lzc_hold(holds, cleanUpFD, &errlist);
	enforce(result ==0, format!"error during holdsnaps: %s"(result));
	return errlist;
}

/+
auto unholdSnapshot(nvlist_t* holds, int cleanupFD)
{
	import std.format:format;
	nvlist_t* errlist;
	auto result = lzc_unhold(holds, cleanUpFD, &errlist);
	enforce(result ==0, format!"error during unholdsnaps: %s"(result));
	return errlist;
}
+/
auto getHeldSnapshots(string snapName)
{
	import std.format:format;
	nvlist_t* holdsp;
	auto result = lzc_get_holds(snapName.toCString, &holdsp);
	enforce(result ==0, format!"error during getHeldSnapshots: %s"(result));
	return holdsp;
}

enum SendFlag
{
	largeBlock = LZC_SEND_FLAG_LARGE_BLOCK,
	embedData = LZC_SEND_FLAG_EMBED_DATA,
	compress = LZC_SEND_FLAG_COMPRESS,
	raw = LZC_SEND_FLAG_RAW
}

void sendSnapshot(string snapshotName, string fromSnapshot, int fileDescriptor, SendFlag[] flags)
{
	import std.algorithm:fold;
	auto lzcFlags = flags.fold!((a,b) => a| b)(cast(SendFlag)0).to!lzc_send_flags;
	auto result = lzc_send(snapshotName.toCString, fromSnapshot.toCString,fileDescriptor,lzcFlags);
	enforce(result == 0, "zfs error");
}

auto sendResume(string snapshotName, string fromSnapshot, int fileDescriptor, SendFlag[] flags, ulong resumeObj, ulong resumeOff)
{
	import std.algorithm:fold;
	auto lzcFlags = flags.fold!((a,b) => a| b)(cast(SendFlag)0).to!lzc_send_flags;
	auto result = lzc_send_resume(snapshotName.toCString, fromSnapshot.toCString, fileDescriptor, lzcFlags, resumeObj, resumeOff);
	enforce(result == 0, "zfs error");
}

@SILdoc(`
"from" can be NULL, a snapshot, or a bookmark.

If from is NULL, a full (non-incremental) stream will be estimated.  This
is calculated very efficiently.

If from is a snapshot, lzc_send_space uses the deadlists attached to
each snapshot to efficiently estimate the stream size.

If from is a bookmark, the indirect blocks in the destination snapshot
are traversed, looking for blocks with a birth time since the creation TXG of
the snapshot this bookmark was created from.  This will result in
significantly more I/O and be less efficient than a send space estimation on
an equivalent snapshot.
`)
auto sendSpace(string snapshotName, string from, SendFlag[] flags)
{
	import std.algorithm:fold;
	auto lzcFlags = flags.fold!((a,b) => a| b)(cast(SendFlag)0).to!lzc_send_flags;
	ulong retSpace;
	auto result = lzc_send_space(snapshotName.toCString, from.toCString, lzcFlags,&retSpace);
	enforce(result == 0, "zfs error");
	return retSpace;
}


/+
*
 * Linux adds ZFS_IOC_RECV_NEW for resumable and raw streams and preserves the
 * legacy ZFS_IOC_RECV user/kernel interface.  The new interface supports all
 * stream options but is currently only used for resumable streams.  This way
 * updated user space utilities will interoperate with older kernel modules.
 *
 * Non-Linux OpenZFS platforms have opted to modify the legacy interface.
 */
int recv_impl(const char *snapname, nvlist_t *recvdprops, nvlist_t *localprops, uint8_t *wkeydata, uint_t wkeylen, const char *origin, boolean_t force, boolean_t resumable, boolean_t raw, int input_fd, const dmu_replay_record_t *begin_record, int cleanup_fd, uint64_t *read_bytes, uint64_t *errflags, uint64_t *action_handle, nvlist_t **errors)

+/

@SILdoc(`zfs receive:
The simplest receive case: receive from the specified fd, creating the
specified snapshot.  Apply the specified properties as "received" properties
(which can be overridden by locally-set properties).  If the stream is a
clone, its origin snapshot must be specified by 'origin'.  The 'force'
flag will cause the target filesystem to be rolled back or destroyed if
necessary to receive.

Return 0 on success or an errno on failure.

Note: this interface does not work on dedupd streams (those with DMU_BACKUP_FEATURE_DEDUP).

resumable: Like lzc_receive, but if the receive fails due to premature stream termination, the intermediate state will be preserved on disk.  In this case, ECKSUM will be returned.  The receive may subsequently be resumed with a resuming send stream generated by lzc_send_resume().
`)
auto zfsReceive(string snapName, string origin, bool force, bool raw, int fileDescriptor, bool resumable = false)
{
	import std.format:format;
	// TODO: For now, we let the properties to be empty.
	auto props = nvlistAlloc(NV_UNIQUE_NAME, 0);
	scope(exit)
		nvlistFree(props);
	auto result = resumable ? lzc_receive(snapName.toCString, props,origin.toCString, force? 1:0, raw?1:0, fileDescriptor) :
			lzc_receive_resumable(snapName.toCString, props,origin.toCString, force?1:0, raw? 1:0, fileDescriptor);
	enforce(result == 0, format!"zfs error: %s"(result));
}

/+
/*
 * Like lzc_receive, but allows the caller to read the begin record and then to
 * pass it in.  That could be useful if the caller wants to derive, for example,
 * the snapname or the origin parameters based on the information contained in
 * the begin record.
 * The begin record must be in its original form as read from the stream,
 * in other words, it should not be byteswapped.
 *
 * The 'resumable' parameter allows to obtain the same behavior as with
 * lzc_receive_resumable.
 */
int
lzc_receive_with_header(const char *snapname, nvlist_t *props,
    const char *origin, boolean_t force, boolean_t resumable, boolean_t raw,
    int fd, const dmu_replay_record_t *begin_record)

*
 * Like lzc_receive, but allows the caller to pass all supported arguments
 * and retrieve all values returned.  The only additional input parameter
 * is 'cleanup_fd' which is used to set a cleanup-on-exit file descriptor.
 *
 * The following parameters all provide return values.  Several may be set
 * in the failure case and will contain additional information.
 *
 * The 'read_bytes' value will be set to the total number of bytes read.
 *
 * The 'errflags' value will contain zprop_errflags_t flags which are
 * used to describe any failures.
 *
 * The 'action_handle' is used to pass the handle for this guid/ds mapping.
 * It should be set to zero on first call and will contain an updated handle
 * on success, it should be passed in subsequent calls.
 *
 * The 'errors' nvlist contains an entry for each unapplied received
 * property.  Callers are responsible for freeing this nvlist.
 */
int lzc_receive_one(const char *snapname, nvlist_t *props, const char *origin, boolean_t force, boolean_t resumable, boolean_t raw, int input_fd, const dmu_replay_record_t *begin_record, int cleanup_fd, uint64_t *read_bytes, uint64_t *errflags, uint64_t *action_handle, nvlist_t **errors)

@SILdoc(`Like lzc_receive_one, but allows the caller to pass an additional 'cmdprops' argument.

The 'cmdprops' nvlist contains both override ('zfs receive -o') and
exclude ('zfs receive -x') properties. Callers are responsible for freeing
this nvlist
`)
auto zfsReceiveWithCommandProperties(string snapName, Property[] properties, Property[] commandProperties, ubyte[] keyData, string origin, bool force, bool resumable, bool raw, int inputFileDescriptor, DmuReplyRecord* beginRecord, int cleanupFileDescriptor)
{
	ulong readBytes;
	ulong errFlags;
	ulong actionHandle;
	nvlist_t* errors;

	auto result = lzc_receive_with_cmdprops(snapName.toCString, properties.asPtr, commandProperties.asPtr, keyData.ptr, keyData.length.to!uint, origin.toCString, force ? 1 :0, resumable ? 1 :0, raw ? 1 : 0, inputFileDescriptor, beginRecord, cleanupFileDescriptor, &readBytes, &errFlags, &actionHandle, &errors);
	enforce(result == 0, format!"zfs error %s"(result));
}

+/

@SILdoc(`Roll back this filesystem or volume to its most recent snapshot
If snapnamebuf is not NULL, it will be filled in with the name of the most recent snapshot.  Note that the latest snapshot may change if a new one is concurrently created or the current one is destroyed.  lzc_rollback_to can be used to roll back to a specific latest snapshot.`)
string rollback(string fsname)
{
	import std.format:format;
	char[16384] buf;
	auto result = lzc_rollback(fsname.toCString, buf.ptr, buf.length.to!int);
	enforce(result ==0, format!"libzfs_core error %s rolling back on %s"(result,fsname));
	return buf.ptr.fromCString.idup;
}

@SILdoc(`Roll back this filesystem or volume to the specified snapshot, if possible`)
void rollbackTo(string fsName, string snapName)
{
	import std.format:format;
	auto result = lzc_rollback_to(fsName.toCString, snapName.toCString);
	enforce(result == 0, format!"zfs error: %s"(result));
}

/+
@SILdoc(`Creates bookmarks.

The bookmarks nvlist maps from name of the bookmark (e.g. "pool/fs#bmark") to
the name of the snapshot (e.g. "pool/fs@snap").  All the bookmarks and
snapshots must be in the same pool.

The returned results nvlist will have an entry for each bookmark that failed.
The value will be the (int32) error code.

The return value will be 0 if all bookmarks were created, otherwise it will
be the errno of a (undetermined) bookmarks that failed.
`)
auto createBookmarks(Bookmark[] bookmarks)
{
	nvlist_t* errlist;
	auto result = lzc_bookmark(bookmarks.asPtr, &errlist);
	enforce(result == 0, format!" zfs error: %s"(result));
}


@SILdoc(`
Retrieve bookmarks.

Retrieve the list of bookmarks for the given file system. The props
parameter is an nvlist of property names (with no values) that will be
returned for each bookmark.

The following are valid properties on bookmarks, all of which are numbers
(represented as uint64 in the nvlist)

"guid" - globally unique identifier of the snapshot it refers to
"createtxg" - txg when the snapshot it refers to was created
"creation" - timestamp when the snapshot it refers to was created

The format of the returned nvlist as follows:
 <short name of bookmark> -> {
    <name of property> -> {
         "value" -> uint64
    }
  }
`)
auto getBookmarks(string fsName, Property[] properties)
{
	nvlist_t* bmarks;
	auto result = lzc_get_bookmarks(fsName.toStringz, properties.asPtr,&bmarks);
	enforce(result == 0, "ZFS error");
	return NvList(bmarks);
}

@SILdoc(`Destroys bookmarks

The keys in the bmarks nvlist are the bookmarks to be destroyed.
They must all be in the same pool.  Bookmarks are specified as
<fs>#<bmark>.

Bookmarks that do not exist will be silently ignored.

The return value will be 0 if all bookmarks that existed were destroyed.

Otherwise the return value will be the errno of a (undetermined) bookmark
that failed, no bookmarks will be destroyed, and the errlist will have an
entry for each bookmarks that failed.  The value in the errlist will be
the (int32) error code.
`)
auto destroyBookmarks(Bookmark[] bookmarks)
{
	nvlist_t* errlist;
	auto result = lzc_destroy_bookmarks(bookmarks.asPtr,&errlist);
	enforce(result == 0, "zfs error");
	return 0;
}

+/
@SILdoc(`Executes a channel program

If this function returns 0 the channel program was successfully loaded and
ran without failing. Note that individual commands the channel program ran
may have failed and the channel program is responsible for reporting such
errors through outnvl if they are important.

This method may also return:

 EINVAL   The program contains syntax errors, or an invalid memory or time
          limit was given. No part of the channel program was executed.
          If caused by syntax errors, 'outnvl' contains information about the
          errors.

 ECHRNG   The program was executed, but encountered a runtime error, such as
          calling a function with incorrect arguments, invoking the error()
          function directly, failing an assert() command, etc. Some portion
          of the channel program may have executed and committed changes.
          Information about the failure can be found in 'outnvl'.

 ENOMEM   The program fully executed, but the output buffer was not large
          enough to store the returned value. No output is returned through
          'outnvl'.

 ENOSPC   The program was terminated because it exceeded its memory usage
          limit. Some portion of the channel program may have executed and
          committed changes to disk. No output is returned through 'outnvl'.

 ETIME    The program was terminated because it exceeded its Lua instruction
          limit. Some portion of the channel program may have executed and
          committed changes to disk. No output is returned through 'outnvl'.
`)
void executeChannelProgram(string pool, string program, ulong instrLimit = ZCP_DEFAULT_INSTRLIMIT, ulong memLimit=ZCP_DEFAULT_MEMLIMIT)
{
	import std.format: format;
	// should pass args
	auto params = nvlistAlloc(NV_UNIQUE_NAME, 0);
	scope(exit)
		nvlistFree(params);
	nvlist_t* outnvl;
	auto result = lzc_channel_program(pool.toCString, program.toCString, instrLimit, memLimit, params,&outnvl);
	enforce(result == 0, format!"zfs error: %s"(result));
}

@SILdoc(`Creates a checkpoint for the specified pool.

If this function returns 0 the pool was successfully checkpointed.

This method may also return:

 ZFS_ERR_CHECKPOINT_EXISTS
	The pool already has a checkpoint. A pools can only have one
    checkpoint at most, at any given time.

 ZFS_ERR_DISCARDING_CHECKPOINT
 	ZFS is in the middle of discarding a checkpoint for this pool.
 	The pool can be checkpointed again once the discard is done.

 ZFS_DEVRM_IN_PROGRESS
 	A vdev is currently being removed. The pool cannot be
 	checkpointed until the device removal is done.

 ZFS_VDEV_TOO_BIG
 	One or more top-level vdevs exceed the maximum vdev size
 	supported for this feature.
`)
void createCheckpoint(string pool)
{
	import std.format:format;
	auto result = lzc_pool_checkpoint(pool.toCString);
	enforce(result == 0, format!"zfs error: %s"(result));
}

@SILdoc(`Discard the checkpoint from the specified pool`)
void discardCheckpoint(string pool)
{
	auto result = lzc_pool_checkpoint_discard(pool.toCString);
	enforce(result != ZFS_ERR_NO_CHECKPOINT, "The pool does not have a checkpoint.");
	enforce(result != ZFS_ERR_DISCARDING_CHECKPOINT, "ZFS is already in the middle of discarding the checkpoint.");
	enforce(result != ZFS_ERR_CHECKPOINT_EXISTS, "ZFS checkpoint already exists");
	//enforce(result != ZFS_DEVRM_IN_PROGRESS,"A vdev is currently being removed");
	//enforce(result != ZFS_VDEV_TOO_BIG,"One or more top-level vdevs exceed max vdev size supported for this feature");
}

/+
@SILdoc(`
Executes a read-only channel program.

A read-only channel program works programmatically the same way as a
normal channel program executed with lzc_channel_program(). The only
difference is it runs exclusively in open-context and therefore can
return faster. The downside to that, is that the program cannot change
on-disk state by calling functions from the zfs.sync submodule.

The return values of this function (and their meaning) are exactly the
same as the ones described in lzc_channel_program().
`)
void executeChannelProgramNoSync(string pool, string program, ulong instrLimit = ZCP_DEFAULT_INSTRLIMIT, ulong memLimit=ZCP_DEFAULT_MEMLIMIT)
{
	import std.format: format;
	// should pass args
	auto params = nvlistAlloc(NV_UNIQUE_NAME, 0);
	scope(exit)
		nvlistFree(params);
	nvlist_t* outnvl;
	auto result = lzc_channel_program_nosync(pool.toCString, program.toCString, timeout, memLimit, params, &outnvl);
	enforce(result == 0, format!"zfs error: %s"(result));
}

+/
/*
 * Performs key management functions
 *
 * crypto_cmd should be a value from dcp_cmd_t. If the command specifies to
 * load or change a wrapping key, the key should be specified in the
 * hidden_args nvlist so that it is not logged.
 */

auto loadKey(string fsName, bool noOp, ubyte[] wkeyData)
{
	import std.format:format;
	auto result = lzc_load_key(fsName.toCString, noOp ? 1 : 0, wkeyData.ptr, wkeyData.length.to!uint);
	enforce(result ==0, format!"loadkey failed with %s"(result));
}

void unloadKey(string fsName)
{
	import std.format:format;
	auto result = lzc_unload_key(fsName.toCString);
	enforce(result ==0, format!"unLoadkey failed with %s"(result));
}


auto changeKey(string fsName, ulong cryptCommand,  ubyte[] wkeyData)
{
	import std.format:format;
	// should pass props
	auto props = nvlistAlloc(NV_UNIQUE_NAME, 0);
	scope(exit)
		nvlistFree(props);
	auto result = lzc_change_key(fsName.toCString, cryptCommand, props,wkeyData.ptr, wkeyData.length.to!uint);
	enforce(result ==0, format!"changeKey failed with %s"(result));
}

void reopen(string pool, bool restartScrub = false)
{
	import std.format:format;
	auto result = lzc_reopen(pool.toCString, restartScrub ? 1 : 0);
	enforce(result ==0, format!"reopen failed with %s"(result));
}



// clone
    // promote
    // destroy_snaps
    // bookmark
    // get_bookmarks
    // destroy_bookmarks
    // snaprange_space
    // hold
    // release
    // get_holds
    // send
    // send_resume
    // send_space
    // receive
    // receive_resumable
    // receive_with_header
    // receive_once
    // receive_with_cmdprops
    // exists
    // rollback
    // rollback_to
    // sync

// TODO Find a better way to find it via zfs lib
string zfsVersion()
{
	import std.process: executeShell;
	import std.string: splitLines, startsWith, strip, join;
	import std.algorithm: filter;
	import std.format:format;

	auto result = executeShell("modinfo zfs");
	enforce(result.status == 0, result.output);
	auto lines = result.output.splitLines.filter!(line => line.startsWith("version:"));
	return lines.front.strip;
}


// Clone from a snapshot. Wrapper for the libzfs_clone.
// TODO: the properties arg are ignored for now, which should be reintroduced.
// add automount
void cloneSnapshot(string from, string target)
{
	import std.format:format;
	auto props = nvlistAlloc(NV_UNIQUE_NAME, 0);
	scope(exit)
		nvlistFree(props);
	auto result = lzc_clone(target.toCString, from.toCString, props);
	enforce(result ==0, format!"failed clone: %s %s %s"(from,target,result));
}

// Exists examine whether the given path to a snapshot exists. Wrapper to the
// lzc_exists.
bool snapshotExists(string path)
{
	return lzc_exists(path.toCString) !=0;
}


// Snapshot takes snapshots. Wrapper for lzc_snapshot.
void snapshot(string[] snapshotNames)
{
	import std.format:format;
	import std.string: join;
	auto snapshots = nvlistAlloc(NV_UNIQUE_NAME, 0);
	foreach(name;snapshotNames)
	{
		nvlistAddBoolean(snapshots,name);
	}

	// TODO: For now, we let the properties to be empty.
	auto props = nvlistAlloc(NV_UNIQUE_NAME, 0);
	scope(exit)
		nvlistFree(props);

	nvlist_t* errList;
	auto result = lzc_snapshot(snapshots, props, &errList);
	if  (result != 0)
	{
		auto ret2 = processErrorList(errList);
		enforce(ret2.length ==0, format!" failed libzfs_core snapshot: %s, %s"(snapshotNames,ret2.join(",")));
	}
}

// DestroySnapshot destroys the snapshots passed in. Wrapper for lzc_destroy_snaps
void destroySnapshots(string[] snapshotNames, bool deferDelete)
{
	import std.format:format;
	import std.string:join;
	auto snapshots = nvlistAlloc(NV_UNIQUE_NAME, 0);
	scope(exit) nvlistFree(snapshots);
	foreach(name;snapshotNames)
	{
		nvlistAddBoolean(snapshots, name);
	}

	nvlist_t* errList;
	boolean_t cdeferDelete = (deferDelete) ? 1 : 0;
	auto result =  lzc_destroy_snaps(snapshots, cdeferDelete, &errList);
	if  (result != 0)
	{
		auto ret2 = processErrorList(errList);
		enforce(ret2.length ==0, format!" failed libzfs_core snapshot: %s, %s"(snapshotNames,ret2.join(",")));
	}
}

// NvlistAlloc is a wrapper for nvlist_alloc.
nvlist_t* nvlistAlloc(uint nvflag, int kmflag)
{
	nvlist_t* cnvlist;
	auto result = nvlist_alloc(&cnvlist, nvflag, kmflag);
	enforce(result ==0, "failed to allocate nvlist");
	return cnvlist;
}

// NvlistFree is a wrapper for nvlist_free.
void nvlistFree(nvlist_t* cnvlist)
{
	nvlist_free(cnvlist);
}

@SILdoc(`Destroy is the wrapper for lzc_destroy`)
ZfsResult destroy(string name)
{
	import std.format:format;
	auto result = lzc_destroy(name.toCString);
	return zfsResult(result==0, ZfsError.noent, format!"failed to destroy %s: %s"(name,result));
}


// Process the error list returned from the libzfs_core functions in the types
// of nvlist_t. The keys are the snapshot names that failed and the values are
// the errno corresponding to each failed snapshot.
string[] processErrorList(nvlist_t* errList)
{
	import std.format:format;
	string[] ret;
	if (isNvlistEmpty(errList)) {
		return ret;
	}

	scope(exit)
		nvlistFree(errList);
	int errNum;
	nvpair_t* elem = nextNvPair(errList);
	while(elem !is null)
	{
		auto s = nvpair_name(elem).fromCString;
		nvpair_value_int32(elem, &errNum);
		ret ~= format!"Failed Snapshot '%s':%s"(s,errNum);
		elem = nvlist_next_nvpair(errList, elem);
	}
	return ret;
}


nvpair_t* nextNvPair(nvlist_t* list, nvpair_t* elemArg = null)
{
	nvpair_t* elem;
	if (elemArg !is null)
		elem = elemArg;
	elem = nvlist_next_nvpair(list, elem);
	return elem;
}


// NvlistAddBoolean is a wrapper for nvlist_add_boolean.
void nvlistAddBoolean(nvlist_t* nvlist, string name)
{
	import std.format:format;
	auto errnoResult = nvlist_add_boolean(nvlist, name.toCString);
	enforce(errnoResult ==0, format!"Failed to add boolean: %s"(errnoResult));
}
// NvlistEmpty is a wrapper for nvlist_empty.
bool isNvlistEmpty(nvlist_t* cnvlist)
{
	return (nvlist_empty(cnvlist) !=0);
}


//void create(string filesystem, DataSetType dataSetType, Property[] properties, ubyte[] wkeyData)
// lzc_create(filesystem.toCString, cast(lzc_dataset_type) dataSetType, properties.asPtr,wkeyData.ptr,wkeyData.length.to!uint_t);

void createFileSystem(string path, void* datasetType=null, void* properties=null, ubyte[] wkeyData =[])
{
	import std.format:format;
	auto props = nvlistAlloc(NV_UNIQUE_NAME, 0);
	enforce(props !is null, "alloc failure for props for "~path );
	scope(exit)
		nvlistFree(props);

	auto cpath = path.toCString;

	auto result = lzc_create(cpath, LZC_DATSET_TYPE_ZFS, props,null,0);
	enforce(result ==0, format!"Failed libzfs_core create: %s"(result));
}

void destroyFileSystem(string path)
{
	throw new Exception("Not implemented");
}

auto getSnapshotSpace() // datalayer.SnapshotSpace)
{
	throw new Exception("Not implemented");
}

auto getFSAndDescendantsSpace(string fs)
{
	// TODO: complete this code
	// return datalayer.DiskSpace{}, fmt.Errorf("Not Implemented")
}

ZfsResult validate(string zpool)
{
	import std.file:exists;
	import std.process:executeShell;
	import std.exception;
	import std.format:format;
	auto result = executeShell("modprobe zfs");
	enforce(result.status==0, "ZFS Kernel module not found");
	return zfsResult(exists(zpool), ZfsError.noent, format!"pool %s not found"(zpool));
}

struct ZfsResult
{
	ZfsError status;
	string message;
}

auto zfsResult(bool success, ZfsError status, string message)
{
	return success ? ZfsResult(ZfsError.success,"") : ZfsResult(status,message);
}


void main(string[] args)
{
	import std.stdio;
	//auto result = validate("tank3");
	// writeln(result);
	auto testSnap = ["tank3/shared/kaleidic@snapfoo"];
	snapshot(testSnap);
	writeln("success creating");
	destroySnapshots(testSnap,false);
	writeln("success destroying");
}

